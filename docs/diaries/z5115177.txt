Week 1

Group was formed and the project selected (ultracast) and meeting times
established. I was selected to be on the backend team. I completed a draft
of the user stories and aim to have them finialised next week as well as
consider possible system architecture solutions.

Week 2

The user stories draft were reviewed at the Tuesday meeting and the tech
stack / system architecture finalised at the Thursday meeting. User stories
were created in JIRA with points and labels assigned. Next week I aim to
complete the user story part of the report. Stories UL-31, UL-32 and UL-33
planned for next sprint.

Week 3

Finished the user story section for the project proposal. Also set up
a basic flask app (UL-31), setup mongodb on a remote server (UL-32) and
setup a basic working example of graph-ql to connect the remote mongodb
instance to the backend webserver (UL-33). JIRAs for next sprint are UL-45,
UL-54.

Week 4

Started using a large data source on podcasts to produce dummy data. Simple
script created to use this data source to create some basic test data. There
is still significant room for improvement with several issues with the current
script. For example, whenever the script is run again (e.g. to in include new fields) 
audio files are reuploaded taking hours for ~20GB of data when the final dataset 
is expected be closer to ~150GB. For the next sprint I aim to improve the script
with the primary change to be avoid reuploading audio files and improved logging
to find what filters are removing most of the test data.

Week 5

The generate test data script now avoids reuploading audio files and logs filtering
so we know what impact the filters are having on the amound of output test data.
I also realised that each download of an episode (often >50MB) can take a noticible
amount of time and graphql doesn't support streaming. For the next sprint I am
going to look into how we can stream our audio to the frontend so the user can have a
low latency experience.

Week 6

The issue of streaming was resolved by creating a remote service which hosts static files 
(Ocean Digitals "Spaces" - like AWS's S3 buckets). The audio tag in html was found to stream 
from files hosted fine. For the next sprint I'm looking at verifying uploads by MIME type
and well as creating a duration field for the podcast episode to record it's length in
seconds.

Week 7

The duration field and verification of uploaded media was successful. We were fortunate 
that the library for checking the file check had the required C library installed on CSE 
as this would have been a difficult challenge otherwise.
I also added the inital backend logic for podcast bookmarks. For the next sprint 
I am going to create the backend logic to do with statistics about views for podcast 
episodes and following other users.

Week 8

The backend logic was created succesfully for views and following other users. At this point
the backend work left is mostly bug fixing. The goal of the next sprint for me is to
primary work on the structure of the upcoming final report but also work on testing 
functionality and recording bugs encountered.

Week 9/10

Did the testing for functionality around staying up to date (UL-7,8,9,30) as well as
the following sections of the report: System Architecture, Functionality to Project
Objectives mapping and the User Manual Functionality guide. Performed testing on 
various features and passed bugs on to Kevin who was fantastic with fixing them.